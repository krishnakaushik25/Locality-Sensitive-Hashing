{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from yaml import CLoader as Loader, load\n",
    "from datasketch import MinHash, MinHashLSHForest\n",
    "\n",
    "from source.model import LSHGraph\n",
    "from source.score import score_fn, get_extn\n",
    "from source.utils import feat_imp, count_fn\n",
    "from source.utils import conv_values, flatten_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config files\n",
    "with open(\"config.yaml\") as stream:\n",
    "    config = load(stream, Loader=Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = config[\"label\"]\n",
    "n_perm = config[\"n_perm\"]\n",
    "thresh = config[\"thresh\"]\n",
    "id_col = config[\"id_col\"]\n",
    "features = config[\"features\"]\n",
    "data_path = config[\"data_path\"]\n",
    "seed_path = config[\"seed_path\"]\n",
    "extn_path = config[\"extn_path\"]\n",
    "list_cols = config[\"list_cols\"]\n",
    "model_path = config[\"model_path\"]\n",
    "count_path = config[\"count_path\"]\n",
    "clean_data_path = config[\"clean_data_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_json(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in data\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to integers\n",
    "for c in features:\n",
    "    if c not in list_cols:\n",
    "        data[c] = data[c].apply(lambda x: x[0] if type(x) == list else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows having number of elements above certain threshold\n",
    "# for list columns\n",
    "for c in list_cols:\n",
    "    data[\"count\"] = data[c].apply(lambda x: len(x) if type(x) == list else 0)\n",
    "    data = data[data[\"count\"] <= thresh]\n",
    "data.drop(\"count\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106546, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the values in the list columns\n",
    "# replace empty values with empty list\n",
    "for c in list_cols:\n",
    "    data[c] = data[c].apply(lambda x: sorted(x) if type(x) == list else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data.rename({\"index\": \"id\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the clean data to disc\n",
    "data.to_json(clean_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature counts for scoring\n",
    "count_df = count_fn(data, features, list_cols)\n",
    "count_df.to_csv(count_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cleaned data\n",
    "data = pd.read_json(clean_data_path)\n",
    "df = data.drop(label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MinHashForest model\n",
    "lsh = MinHashLSHForest(num_perm=n_perm)\n",
    "# Create a LSH graph object\n",
    "lsh_graph = LSHGraph(df, lsh, features,\n",
    "                     id_col=id_col,\n",
    "                     n_perm=n_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 of 106546\n",
      "Processing 5000 of 106546\n",
      "Processing 10000 of 106546\n",
      "Processing 15000 of 106546\n",
      "Processing 20000 of 106546\n",
      "Processing 25000 of 106546\n",
      "Processing 30000 of 106546\n",
      "Processing 35000 of 106546\n",
      "Processing 40000 of 106546\n",
      "Processing 45000 of 106546\n",
      "Processing 50000 of 106546\n",
      "Processing 55000 of 106546\n",
      "Processing 60000 of 106546\n",
      "Processing 65000 of 106546\n",
      "Processing 70000 of 106546\n",
      "Processing 75000 of 106546\n",
      "Processing 80000 of 106546\n",
      "Processing 85000 of 106546\n",
      "Processing 90000 of 106546\n",
      "Processing 95000 of 106546\n",
      "Processing 100000 of 106546\n",
      "Processing 105000 of 106546\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "lsh_graph.update_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disc\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(lsh_graph, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed set extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cleaned data\n",
    "data = pd.read_json(clean_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the seed set\n",
    "seed = pd.read_csv(seed_path)\n",
    "seed_ids = list(seed[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "lsh_graph = pickle.load(open(model_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the neighbors of seed set from LSH graph\n",
    "neighbors = lsh_graph.extract_neighbors(seed_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select records that are not in the seed set\n",
    "df = data[~data[\"id\"].isin(seed_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the default click rate\n",
    "def_click_rate = df[label].mean()\n",
    "def_click_rate = round(def_click_rate*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the neighbors\n",
    "df = score_fn(data, count_path, features, list_cols,\n",
    "              seed_ids, neighbors, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and store extension file\n",
    "extn_click_rate = get_extn(df, seed_ids, label, extn_path, x=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click rate increased from 9.24% to 13.82%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Click rate increased from {def_click_rate}% to {extn_click_rate}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
